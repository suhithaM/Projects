{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "35ac6045-6c6c-4ad2-98aa-12b333246847",
   "metadata": {},
   "outputs": [],
   "source": [
    "COLLECTING DATA USING WEB SCRAPPING"
   ]
  },
  {
   "cell_type": "raw",
   "id": "f655bd4b-d3f5-4962-849a-622af37b1514",
   "metadata": {},
   "source": [
    "Scrape www.ibm.com"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0ab991b1-c1eb-462b-8064-9bff5a3b96e5",
   "metadata": {},
   "source": [
    "Import the required modules and functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "001d0d7c-4af6-435c-b9b0-0e381bc99a77",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting pandas\n",
      "  Downloading pandas-2.2.2-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (19 kB)\n",
      "Collecting numpy>=1.23.2 (from pandas)\n",
      "  Downloading numpy-2.1.1-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (60 kB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m60.9/60.9 kB\u001b[0m \u001b[31m7.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hRequirement already satisfied: python-dateutil>=2.8.2 in /opt/conda/lib/python3.11/site-packages (from pandas) (2.9.0)\n",
      "Requirement already satisfied: pytz>=2020.1 in /opt/conda/lib/python3.11/site-packages (from pandas) (2024.1)\n",
      "Collecting tzdata>=2022.7 (from pandas)\n",
      "  Downloading tzdata-2024.1-py2.py3-none-any.whl.metadata (1.4 kB)\n",
      "Requirement already satisfied: six>=1.5 in /opt/conda/lib/python3.11/site-packages (from python-dateutil>=2.8.2->pandas) (1.16.0)\n",
      "Downloading pandas-2.2.2-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (13.0 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m13.0/13.0 MB\u001b[0m \u001b[31m117.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m0:01\u001b[0m\n",
      "\u001b[?25hDownloading numpy-2.1.1-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (16.3 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m16.3/16.3 MB\u001b[0m \u001b[31m117.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m00:01\u001b[0m\n",
      "\u001b[?25hDownloading tzdata-2024.1-py2.py3-none-any.whl (345 kB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m345.4/345.4 kB\u001b[0m \u001b[31m41.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hInstalling collected packages: tzdata, numpy, pandas\n",
      "Successfully installed numpy-2.1.1 pandas-2.2.2 tzdata-2024.1\n"
     ]
    }
   ],
   "source": [
    "!pip install pandas"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "fad5ab24-e1bd-4e8e-b347-5cd5697e51ec",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from bs4 import BeautifulSoup\n",
    "import requests"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "459082ba-aa6a-482b-9735-80f305625373",
   "metadata": {},
   "source": [
    "Download the contents of the web page"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "af31d855-ab55-4be9-9da0-530135fbb487",
   "metadata": {},
   "outputs": [],
   "source": [
    "url = \"http://www.ibm.com\"\n",
    "data = requests.get(url).text  #store contents of webpage in variable called data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "e6bf485d-b2e4-434c-a539-b03fc53c96b6",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Create a soup object using the class BeautifulSoup\n",
    "soup = BeautifulSoup(data, \"html.parser\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "b717637c-c806-4715-ac2d-d62fd0e29baa",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "All Links:\n",
      "https://www.ibm.com/hybrid-cloud?lnk=hpUSbt1\n",
      "https://www.ibm.com/consulting\n"
     ]
    }
   ],
   "source": [
    "print(\"All Links:\")\n",
    "for link in soup.find_all('a'):  # find all anchor tags <a>\n",
    "    href = link.get('href')\n",
    "    if href:  # sometimes href can be None\n",
    "        print(href)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "2b4aa62d-d2b4-4372-854e-2f3452fe4e6d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "All Images:\n"
     ]
    }
   ],
   "source": [
    "print(\"\\nAll Images:\")\n",
    "for img in soup.find_all('img'):  # find all image tags <img>\n",
    "    src = img.get('src')\n",
    "    if src:  # sometimes src can be None\n",
    "        print(src)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e9999001-26f8-4248-aba7-4d60d1509002",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "660cf07a-4c26-49bb-a1b5-0cd3adcf6b93",
   "metadata": {},
   "source": [
    "Scrape data from html tables"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0b6fb59d-745e-4aaa-b630-645767839bbd",
   "metadata": {},
   "source": [
    "#We will extract data from below url that contains a html table with data about colors and color codes."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "1f7dc80e-11cf-430e-b20e-9d0a00d7de58",
   "metadata": {},
   "outputs": [],
   "source": [
    "url = \"https://cf-courses-data.s3.us.cloud-object-storage.appdomain.cloud/IBM-DA0321EN-SkillsNetwork/labs/datasets/HTMLColorCodes.html\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "eb0494e1-941e-43f7-8fbb-a07d48981b44",
   "metadata": {},
   "outputs": [],
   "source": [
    "# get the contents of the webpage in text format and store in a variable called data\n",
    "data  = requests.get(url).text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "71cc15f2-a5b1-4bf0-8285-d705dde46067",
   "metadata": {},
   "outputs": [],
   "source": [
    "soup = BeautifulSoup(data,\"html.parser\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "b75ac7e9-21d9-4c84-89ef-8c79ee8bfd31",
   "metadata": {},
   "outputs": [],
   "source": [
    "#find a html table in the web page\n",
    "table = soup.find('table')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "9dcfc39f-4b94-4f70-beab-7b9770463ed3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Color Name ---> Hex Code#RRGGBB\n",
      "lightsalmon ---> #FFA07A\n",
      "salmon ---> #FA8072\n",
      "darksalmon ---> #E9967A\n",
      "lightcoral ---> #F08080\n",
      "coral ---> #FF7F50\n",
      "tomato ---> #FF6347\n",
      "orangered ---> #FF4500\n",
      "gold ---> #FFD700\n",
      "orange ---> #FFA500\n",
      "darkorange ---> #FF8C00\n",
      "lightyellow ---> #FFFFE0\n",
      "lemonchiffon ---> #FFFACD\n",
      "papayawhip ---> #FFEFD5\n",
      "moccasin ---> #FFE4B5\n",
      "peachpuff ---> #FFDAB9\n",
      "palegoldenrod ---> #EEE8AA\n",
      "khaki ---> #F0E68C\n",
      "darkkhaki ---> #BDB76B\n",
      "yellow ---> #FFFF00\n",
      "lawngreen ---> #7CFC00\n",
      "chartreuse ---> #7FFF00\n",
      "limegreen ---> #32CD32\n",
      "lime ---> #00FF00\n",
      "forestgreen ---> #228B22\n",
      "green ---> #008000\n",
      "powderblue ---> #B0E0E6\n",
      "lightblue ---> #ADD8E6\n",
      "lightskyblue ---> #87CEFA\n",
      "skyblue ---> #87CEEB\n",
      "deepskyblue ---> #00BFFF\n",
      "lightsteelblue ---> #B0C4DE\n",
      "dodgerblue ---> #1E90FF\n"
     ]
    }
   ],
   "source": [
    "# To get all rows from the table, iterate over all rows in the table\n",
    "for row in table.find_all('tr'): \n",
    "    # Get all columns in each row\n",
    "    cols = row.find_all('td')\n",
    "    #if len(cols) = 5:  # ensure there are enough columns in the row\n",
    "    color_name = cols[2].getText()  # store the value in column 3 as color_name\n",
    "    color_code = cols[3].getText()  # store the value in column 4 as color_code\n",
    "    print(\"{} ---> {}\".format(color_name, color_code))  # print the color name and code"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "d3adc6b5-d7c0-426a-b8a8-52ea9c5470c8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Color Name ---> Hex Code#RRGGBB\n",
      "lightsalmon ---> #FFA07A\n",
      "salmon ---> #FA8072\n",
      "darksalmon ---> #E9967A\n",
      "lightcoral ---> #F08080\n",
      "coral ---> #FF7F50\n",
      "tomato ---> #FF6347\n",
      "orangered ---> #FF4500\n",
      "gold ---> #FFD700\n",
      "orange ---> #FFA500\n",
      "darkorange ---> #FF8C00\n",
      "lightyellow ---> #FFFFE0\n",
      "lemonchiffon ---> #FFFACD\n",
      "papayawhip ---> #FFEFD5\n",
      "moccasin ---> #FFE4B5\n",
      "peachpuff ---> #FFDAB9\n",
      "palegoldenrod ---> #EEE8AA\n",
      "khaki ---> #F0E68C\n",
      "darkkhaki ---> #BDB76B\n",
      "yellow ---> #FFFF00\n",
      "lawngreen ---> #7CFC00\n",
      "chartreuse ---> #7FFF00\n",
      "limegreen ---> #32CD32\n",
      "lime ---> #00FF00\n",
      "forestgreen ---> #228B22\n",
      "green ---> #008000\n",
      "powderblue ---> #B0E0E6\n",
      "lightblue ---> #ADD8E6\n",
      "lightskyblue ---> #87CEFA\n",
      "skyblue ---> #87CEEB\n",
      "deepskyblue ---> #00BFFF\n",
      "lightsteelblue ---> #B0C4DE\n",
      "dodgerblue ---> #1E90FF\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "['Color Name , Hex Code#RRGGBB',\n",
       " 'lightsalmon , #FFA07A',\n",
       " 'salmon , #FA8072',\n",
       " 'darksalmon , #E9967A',\n",
       " 'lightcoral , #F08080',\n",
       " 'coral , #FF7F50',\n",
       " 'tomato , #FF6347',\n",
       " 'orangered , #FF4500',\n",
       " 'gold , #FFD700',\n",
       " 'orange , #FFA500',\n",
       " 'darkorange , #FF8C00',\n",
       " 'lightyellow , #FFFFE0',\n",
       " 'lemonchiffon , #FFFACD',\n",
       " 'papayawhip , #FFEFD5',\n",
       " 'moccasin , #FFE4B5',\n",
       " 'peachpuff , #FFDAB9',\n",
       " 'palegoldenrod , #EEE8AA',\n",
       " 'khaki , #F0E68C',\n",
       " 'darkkhaki , #BDB76B',\n",
       " 'yellow , #FFFF00',\n",
       " 'lawngreen , #7CFC00',\n",
       " 'chartreuse , #7FFF00',\n",
       " 'limegreen , #32CD32',\n",
       " 'lime , #00FF00',\n",
       " 'forestgreen , #228B22',\n",
       " 'green , #008000',\n",
       " 'powderblue , #B0E0E6',\n",
       " 'lightblue , #ADD8E6',\n",
       " 'lightskyblue , #87CEFA',\n",
       " 'skyblue , #87CEEB',\n",
       " 'deepskyblue , #00BFFF',\n",
       " 'lightsteelblue , #B0C4DE',\n",
       " 'dodgerblue , #1E90FF']"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "table = soup.find('table')\n",
    "html_supported_colors = []\n",
    "\n",
    "# To get all rows from the table, iterate over all rows in the table\n",
    "for row in table.find_all('tr'): \n",
    "    # Get all columns in each row\n",
    "    cols = row.find_all('td')\n",
    "    #if len(cols) = 5:  # ensure there are enough columns in the row\n",
    "    color_name = cols[2].getText()  # store the value in column 3 as color_name\n",
    "    color_code = cols[3].getText()  # store the value in column 4 as color_code\n",
    "    print(\"{} ---> {}\".format(color_name, color_code))  # print the color name and code\n",
    "    html_supported_colors.append(str(color_name) + ' , ' + str(color_code).replace('$','').replace(',',''))\n",
    "\n",
    "html_supported_colors"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "1980d4a5-645b-4bda-a9b6-0895ec5165a1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# We save the scrapped data into a file named 2.b1Supported_colors(from WebScraping).csv\n",
    "df = pd.DataFrame(html_supported_colors)\n",
    "df.to_csv('Supported_colors(from WebScraping).csv',header=False, index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fcc9c092-6f36-4df6-91d2-29d6e3ebaa35",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
